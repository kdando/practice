############################################
USER_FUNCTIONS.PY
############################################

import re
from collections import Counter
import spacy
word2vec = spacy.load('en')
from nltk import pos_tag
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
stop_words = set(stopwords.words("english"))

### Makes sentence lower case. Replaces letter, space, at the beggining of string with nothing (so deletes "I", etc).
Tokenizes the sentence. Removes stopwords from tokenized sentence. ###

def preprocess(input_sentence):
    input_sentence = input_sentence.lower()
    input_sentence = re.sub(r'[^\w\s]','',input_sentence)
    tokens = word_tokenize(input_sentence)
    input_sentence = [i for i in tokens if not i in stop_words]
    return(input_sentence)

### Counts words that appear in both given args ###

def compare_overlap(user_message, possible_response):
    similar_words = 0
    for token in user_message:
        if token in possible_response:
              similar_words += 1
    return similar_words
 
### POS-tagged tokens are tuples with two items - the word and the POS tag. This checks if the POS tag (item at index 1 in the tuple) starts with N - i.e. is a noun. If it is it gets added to the message_nouns list. ###

def extract_nouns(tagged_message):
    message_nouns = list()
    for token in tagged_message:
        if token[1].startswith("N"):
            message_nouns.append(token[0])
    return message_nouns

### Creates a list of lists, wherein there are 3 items per inner list - the token (as string), the category (as string), and the token's similarity to the category (as number). ###

def compute_similarity(tokens, category):
    output_list = list()
    for token in tokens:
        output_list.append([token.text, category.text, token.similarity(category)])
    return output_list
  
############################################
RESPONSES.PY
############################################

response_a = "The {} has a gluten-free option, but it is not vegan"
response_b = "We have a selection of sides to go along with the {}, including mashed potatoes and steamed vegatables."
response_c = "{} includes habanero, so it is a bit spicy!"
response_d = "The only {} is the rice."
blank_spot = "food"


responses = [response_a, response_b, response_c, response_d]

############################################
SCRIPT.PY
############################################

from collections import Counter
from responses import responses, blank_spot
from user_functions import preprocess, compare_overlap, pos_tag, extract_nouns, compute_similarity
import spacy
word2vec = spacy.load('en')

exit_commands = ("quit", "goodbye", "exit", "no")

class ChatBot:
  
  ###CALLED IN PARALLEL TO .RESPOND(), CONSTANTLY
  def make_exit(self, user_message):
    for item in exit_commands:
      if item in user_message:
        print("See you, space cowboy... ")
        return True
      
  #### CALLED FIRST...
  def chat(self):
    user_message = input("Hola, how can I help? ")
    while not(self.make_exit(user_message)):
      user_message = self.respond(user_message)
  
  #### CALLED THIRD...
  def find_intent(self, responses, user_message):
    bow_user_message = Counter(preprocess(user_message))
    processed_response = [ Counter(preprocess(item)) for item in responses ]
    similarity_list = [ compare_overlap(item, bow_user_message) for item in processed_response ]
    response_index = similarity_list.index(max(similarity_list))
    return responses[response_index]
 
  #### CALLED FOURTH...
  def find_entities(self, user_message):
    tagged_user_message = pos_tag(preprocess(user_message))
    user_message_nouns = extract_nouns(tagged_user_message)
    tokens = word2vec(" ".join(user_message_nouns))
    category = word2vec(blank_spot)
    word2vec_similarity_result = compute_similarity(tokens, category)
    word2vec_similarity_result.sort(key=lambda x: x[2])
    if len(word2vec_similarity_result) < 1:
      return blank_spot
    else:
      return word2vec_similarity_result[-1][0]
 
  #### CALLED SECOND...
  def respond(self, user_message):
    best_response = self.find_intent(responses, user_message)
    entity = self.find_entities(user_message)
    print(best_response.format(entity))
    input_message = input("Anything else? ")
    return input_message

#initialize ChatBot instance below:
servir = ChatBot()

#call .chat() method below:
servir.chat()

