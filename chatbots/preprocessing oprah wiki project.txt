from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.stem import WordNetLemmatizer
from part_of_speech import get_part_of_speech
import re

lemmatizer = WordNetLemmatizer()

oprah_wiki = '<p>Working in local media, she was both the youngest news anchor and the first black female news anchor at Nashville\'s WLAC-TV. </p>'

oprah_trim = re.sub("<.?p>|\.|\'|,", "", oprah_wiki)
oprah_low = oprah_trim.lower()
oprah_token = word_tokenize(oprah_low)

oprah_lem = [ lemmatizer.lemmatize(word, get_part_of_speech(word)) for word in oprah_token ]

print(oprah_lem)

# Final output:

['work', 'in', 'local', 'medium', 'she', 'be', 'both', 'the', 'young', 'news', 'anchor', 'and', 'the', 'first', 'black', 'female', 'news', 'anchor', 'at', 'nashville', 'wlac-tv']